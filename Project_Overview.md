PROJECT OVERVIEW - ModifyMe Consulting Agent Workspaces
UPDATED: 01/01/2025

**Here is a high-level concept of what I want to achieve (please note - some key conceptual changes have been made to this plan, please ensure the Project Overview below is only considered as a direction/vision rather than a blueprint**

# Generative UI Workspace ğŸš€  

**Agentic, multi-surface Generative UI for data & workflows â€” built on Next.js, CopilotKit, and Material UI.**

> **Build systems that build interfaces.**  
> This workspace is a GenUI R&D and implementation lab: it combines CopilotKitâ€™s Generative UI patterns, a Next.js app, and an agentic backend to let AI generate dashboards, tools, and â€œdisposable UIsâ€ from natural language â€” safely, consistently, and with enterprise-grade guardrails.

---

## ğŸ¯ What Is This?

A **Generative UI workspace** for designing, prototyping, and operationalizing AIâ€‘generated interfaces:

- **Next.js + CopilotKit GenUI**: Streaming, agentic chat + canvas with server-side orchestration
- **Static + Declarative + Openâ€‘Ended GenUI**: From safe component routing to sandboxed HTML/JS
- **MUIâ€‘backed Component Registry**: Opinionated library of reusable â€œmoleculesâ€ for charts, cards & tables
- **Sandboxed HTML Canvas**: Isolated iframe runtime for openâ€‘ended UI experiments
- **Architecture Blueprints**: Deep architectural docs for AGâ€‘UI, Chat+, and multi-layer GenUI systems

This workspace is optimized for **architecting and validating a GenUI stack**, not just demoing a single app. Itâ€™s where you:

- Design agent â†’ UI protocols (AGâ€‘UI style)
- Build a component registry that AI can reliably use
- Experiment with safe openâ€‘ended code generation in a sandbox
- Evaluate UX patterns like Chat+, AI Elements, and Ghost UI

---

## ğŸ“š Documentation & Reference

### Core Concepts & Architecture

- **[Implementing Generative UI Architecture](./Implementing%20Generative%20UI%20Architecture.md)**  
  Deep dive into GenUI layers: Cognitive, Orchestration, Presentation; Static vs Declarative vs Openâ€‘Ended; AGâ€‘UI patterns.

- **[Generative UI Plan with CopilotKit](./Generative%20UI%20Plan%20with%20CopilotKit.md)**  
  Endâ€‘toâ€‘end implementation plan: Next.js + CopilotKit + MUI, Chat+ canvas, sandboxing, AI Elements, evaluation strategy.

- **GenUI Starter Plan** (`GenUI_Plan.md`)  
  Highâ€‘level file map and external references:
  - Generative UI starter app structure
  - CopilotKit Generative UI docs
  - MUI / Toolpad / CRUD template references
  - AgenticGenUI / AI Elements links

### CopilotKit Prompts (GenUI â€œOSâ€)

Under `prompts/copilot/` (from the starter):

- `01_molecules.md` â€” defines component vocabulary (cards, stats, tables)
- `02_tools_and_routes.md` â€” tool calling and backend routing patterns
- `03_canvas_and_state.md` â€” Chat+ canvas, state sync, agentic updates
- `04_tests.md` â€” testing + evaluation prompts
- `05_sandboxed_open_ended.md` â€” safe openâ€‘ended HTML/JS generation
- `06_refactoring.md` â€” iterative improvement and refactors

These prompts act as the **Cognitive Layer specification** â€” the instruction â€œOSâ€ that tells the model how to think about UI, state, tools, and safety.

---

## ğŸ“‚ Project Structure (Conceptual)

This workspace is anchored around a **GenUI starter** with a Next.js app, CopilotKit integration, and a small but expressive set of generative components.

```text
genui-starter/
â”œâ”€ README.md
â”œâ”€ app/
â”‚  â”œâ”€ api/
â”‚  â”‚  â””â”€ chat/
â”‚  â”‚     â””â”€ route.ts           # CopilotKit backend / Edge entry for LLM + tools
â”‚  â””â”€ canvas/
â”‚     â””â”€ GenerativeCanvas.tsx  # Chat+ style persistent canvas for GenUI
â”œâ”€ components/
â”‚  â”œâ”€ ai/
â”‚  â”‚  â””â”€ StreamingSkeleton.tsx # Generative streaming & AI Elements skeletons
â”‚  â”œâ”€ registry/
â”‚  â”‚  â”œâ”€ StatCard.tsx          # MUIâ€‘style metric cards (Static GenUI molecule)
â”‚  â”‚  â”œâ”€ DataTable.tsx         # Data grid / table molecule
â”‚  â”‚  â””â”€ ChartCard.tsx         # Chart wrapper (e.g., Recharts/Chart.js)
â”‚  â”œâ”€ renderers/
â”‚  â”‚  â””â”€ DashboardRenderer.tsx # Declarative schema â†’ component layout renderer
â”‚  â””â”€ sandbox/
â”‚     â””â”€ SandboxedHTML.tsx     # Iframe sandbox for Openâ€‘Ended GenUI (HTML/JS)
â”œâ”€ lib/
â”‚  â”œâ”€ copilotkit/
â”‚  â”‚  â””â”€ hooks.ts              # useRenderTool, useCopilotReadable, etc.
â”‚  â””â”€ schema/
â”‚     â””â”€ dashboard.ts          # Declarative dashboard / widget schemas (AGâ€‘UI-style)
â””â”€ prompts/
   â””â”€ copilot/
      â”œâ”€ 01_molecules.md
      â”œâ”€ 02_tools_and_routes.md
      â”œâ”€ 03_canvas_and_state.md
      â”œâ”€ 04_tests.md
      â”œâ”€ 05_sandboxed_open_ended.md
      â””â”€ 06_refactoring.md
```

In addition, the broader repo (`Ditto190/ag2`) includes:

- **Devcontainer for Generative UI**:  
  `.devcontainer/generative-ui/devcontainer.json` â€” Python 3.11 + Node 20 devcontainer tailored for GenUI + AG2 experiments (Next.js on 3000, FastAPI on 8000, multiâ€‘provider LLM secrets).

- **AG2 / Agentic Infrastructure** (outside this docâ€™s scope) that you can integrate as backends or tools for GenUI.

---

## ğŸ§  Architectural Approach

This workspace is built around a **Hybrid Generative UI Architecture**:

1. **Static GenUI (Component Router)**  
   - Safe, productionâ€‘grade UI via a curated component registry (MUIâ€‘style cards, tables, charts).
   - The agent selects components and populates props, not raw DOM.
   - Ideal for dashboards, CRUD tools, reporting views.

2. **Declarative GenUI (Schema â†’ Renderer)**  
   - Agent outputs JSON schemas (layouts, widgets, data bindings).
   - `DashboardRenderer` + `dashboard.ts` turn schemas into React trees.
   - Balances flexibility with control; all layout passes through known primitives.

3. **Openâ€‘Ended GenUI (Sandboxed Canvas)**  
   - For prompts that escape the registry / schema (games, fractal explorers, novel visualizations).
   - HTML/CSS/JS generated into an isolated iframe (`SandboxedHTML`), with:
     - sandbox + strict CSP
     - limited, curated runtime (e.g., React, Tailwind, chart libs) preâ€‘loaded
     - communication via `postMessage` with a narrow, typed protocol
   - High freedom, but contained blast radius.

All three share a **common state & event model** (AGâ€‘UI style), enabling:

- Chatâ€‘based negotiation of intent (â€œChat surfaceâ€)
- A persistent generative canvas (â€œChat+ surfaceâ€)
- Headless hints and suggestions in existing apps (â€œChatless surfaceâ€) when integrated into other systems

---

## ğŸ§© Key Features

| Area | Feature | Status |
|------|---------|--------|
| **Core GenUI** | Agentic chat endpoint (CopilotKit + Next.js API route) | ğŸ§ª In progress |
| | Chat+ canvas (`GenerativeCanvas`) | ğŸ§ª In progress |
| **Component Registry** | MUIâ€‘style StatCard, DataTable, ChartCard | ğŸ§ª Prototyping |
| | Dashboard schema & renderer | ğŸ§ª Prototyping |
| **Openâ€‘Ended UI** | Sandboxed HTML iframe with strict isolation | ğŸ§ª Design phase |
| | Prompting for Tailwindâ€‘style HTML/JS generation | ğŸ§ª Design phase |
| **AI Orchestration** | CopilotKit hooks for tools & readable state | âœ… Patterns defined (see docs) |
| | AGâ€‘UI style event & state synchronization | ğŸ§ª Design / spec phase |
| **UX / AI Elements** | Streaming skeletons for generative slots | ğŸ§ª Prototyping (`StreamingSkeleton.tsx`) |
| | Ghost UI, suggestion chips for next actions | ğŸ§ª Planned |
| **Evaluation** | PAGENâ€‘style GenUI benchmark prompts | ğŸ§ª Planned |
| | Human / LLMâ€‘judge ELO scoring | ğŸ§ª Planned |

---

## ğŸš€ Quick Start (Conceptual)

> Exact commands will depend on how you instantiate `genui-starter/`, but the flow is:

1. **Open Devcontainer (Optional but Recommended)**  
   Use `.devcontainer/generative-ui/devcontainer.json` in `Ditto190/ag2` to get:
   - Node 20
   - VS Code extensions for TS/React/Tailwind
   - Autoâ€‘forwarded ports: 3000 (Next.js), 8000 (backend/LLM if needed)

2. **Install Frontend Dependencies**

```bash
# From genui-starter root
pnpm install   # or npm/yarn
```

1. **Configure LLM / CopilotKit Backend**

- Point `app/api/chat/route.ts` to your LLM provider(s) and CopilotKit runtime.
- Wire in prompts from `prompts/copilot/*.md` (molecules, tools, canvas, sandbox).

1. **Run the Dev Server**

```bash
pnpm dev
# Next.js app at http://localhost:3000
```

1. **Try a GenUI Conversation**

- Open the app.
- In chat, ask:  
  > â€œCreate a sales KPI dashboard with three stat cards and a table of top customers.â€
- Watch the agent:
  - Interpret intent
  - Call registry tools (StatCard, DataTable)
  - Render into chat and/or the `GenerativeCanvas`

---

## ğŸ“ Usage Patterns

### 1. Static GenUI (Component Registry)

Use when you want **reliable, branded, testable** UI.

- Tools map directly to registry components:
  - `render_stat_card`
  - `render_chart_card`
  - `render_data_table`
- Zod schemas + CopilotKit hooks enforce types and prevent hallucinated props.
- Good for:
  - KPI dashboards
  - CRUD views
  - Standard reporting UIs

### 2. Declarative GenUI (Dashboard Schemas)

Use when you want **flexible layouts** from structured definitions.

- Agent emits a JSON schema defined in `lib/schema/dashboard.ts`, e.g.:

```jsonc
{
  "layout": "3-column",
  "widgets": [
    { "type": "stat", "title": "MRR", "value": 120000 },
    { "type": "chart", "kind": "line", "metric": "Revenue" },
    { "type": "table", "source": "top_customers" }
  ]
}
```

- `DashboardRenderer` translates this to a MUI Grid of registry components.

### 3. Openâ€‘Ended GenUI (SandboxedHTML)

Use when the user asks for something outside your registry/schema vocabulary.

- Examples:
  - â€œBuild a fractal explorer where I can zoom with the mouse wheel.â€
  - â€œMake a small game to teach binary numbers.â€

- Flow:
  1. Agent uses openâ€‘ended HTML/JS generation prompt (see `05_sandboxed_open_ended.md`).
  2. Output is rendered inside `SandboxedHTML`:
     - iframe with `sandbox` + CSP
     - no access to parent window or cookies
     - only preâ€‘approved libs available
  3. `postMessage` used for controlled communication (resize, events, analytics).

---

## ğŸ” Safety, Security & Control

Generative UI has real risks: broken UX, hallucinated data, XSS. This workspace is architected with layered defenses:

- **Component Registry**: Most UIs are built from audited, testable registry components.
- **Schemas & Validation**:
  - Zod schemas define the contract between agent and UI.
  - Invalid tool calls are rejected before rendering.
- **Sandboxing**:
  - All openâ€‘ended HTML/JS is isolated in an iframe with strict sandbox attributes and CSP.
  - Only curated libraries and assets allowed in the sandbox.
  - Communication limited to a typed `postMessage` protocol.
- **Fact Verification & Metadata (planned)**:
  - Agents instructed to fetch data via tools / RAG, not from stale training data.
  - UIs can show â€œsource metadataâ€ (e.g., URL, query) for critical numbers.

---

## ğŸ§± Tech Stack

### Frontend & Orchestration

- **Next.js (App Router)** â€” Streaming, server components, edge runtimes.
- **React 18+** â€” Component model, Suspense, concurrent rendering.
- **CopilotKit** â€” Agent orchestration, generative UI hooks, Chat+ integration.
- **TypeScript** â€” Strong typing across tools, schemas, and components.
- **MUI (Material UI)** â€” Accessible, themeable primitives for the component registry.
- **(Optional) Tailwind CSS** â€” For openâ€‘ended sandboxed UIs.

### Agentic & Backend

- **LLMs** â€” Gemini / OpenAI / Anthropic / others, wired via CopilotKit / AG2 style runtimes.
- **Node / Edge Runtime** â€” For lowâ€‘latency orchestration and streaming.

---

## ğŸš§ Current Status & Next Steps

### âœ… Established

- Architecture for:
  - Static vs Declarative vs Openâ€‘Ended GenUI
  - Chat+ surface (chat + canvas)
  - Sandbox and security model
- Conceptual component registry design (StatCard, DataTable, ChartCard)
- Prompt sets for molecules, tools, routes, canvas, testing, sandboxing

### ğŸ§ª In Progress

- Implementing the initial GenUI starter (Next.js app + CopilotKit + registry)
- Wiring prompts into the CopilotKit runtime
- Implementing `StreamingSkeleton` and streaming UX patterns

### ğŸ”œ Planned

1. **Registry Expansion**  
   - Add more molecules (filters, multiâ€‘step wizards, timelines)
   - Harden DataTable and ChartCard for real datasets

2. **State & AGâ€‘UI Integration**  
   - Implement `useCopilotReadable` across key components
   - Define a minimal AGâ€‘UI event/state protocol for canvas interactions

3. **Openâ€‘Ended Engine**  
   - Finalize sandbox runtime (curated libs, CSP, postMessage protocol)
   - Add selfâ€‘healing loop for runtime errors in generated code

4. **Evaluation & Benchmarks**  
   - Create a domainâ€‘specific PAGENâ€‘style prompt suite
   - Establish GenUI ELO scoring with human / LLM judges

---

## ğŸ¤” Why This Workspace?

Traditional UI workspaces are about **designing fixed screens**.  
This workspace is about **designing the system that designs the screens**.

Use it to:

- Prototype new GenUI patterns (Chat+, Ghost UI, AGâ€‘UI)
- Experiment with mixing safe static components and wild openâ€‘ended canvases
- Build a reusable blueprint that you can transplant into consulting projects, internal tools, or data apps that need â€œonâ€‘demandâ€ interfaces.

---

**Next step:**  
Open the GenUI starter, wire up the chat route with your LLM, and implement the first endâ€‘toâ€‘end flow:

> â€œGenerate a threeâ€‘card KPI summary and a table for my sample dataset.â€

From there, evolve the registry, schema, and sandbox â€” youâ€™re building the **Agentic Interface layer** for your future apps.
